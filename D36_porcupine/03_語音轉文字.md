# èªéŸ³è½‰æ–‡å­—

_åˆ† `å®˜æ–¹` èˆ‡ `éå®˜æ–¹` ç‰ˆæœ¬å¯¦ä½œ_

<br>

## å®‰è£å·¥å…·

_èªéŸ³è½‰æ–‡å­—å·¥å…· `Whisper`_

<br>

1. æ¡ç”¨ OpenAI çš„ [Whisper](https://github.com/openai/whisper)ï¼Œé€™æ˜¯ä¸€æ¬¾é–‹æºã€æ•ˆæœæ¥µä½³çš„èªéŸ³è¾¨è­˜æ¨¡å‹ï¼›`Whisper` æœƒä½¿ç”¨ `ffmpeg` è™•ç†éŸ³è¨Šæ ¼å¼ï¼Œæ‰€ä»¥æœƒä¸€èµ·å®‰è£ã€‚

    ```bash
    sudo apt install ffmpeg sox libsox-fmt-all -y
    pip install openai-whisper
    ```

<br>

## æ¸¬è©¦èªéŸ³è¾¨è­˜

1. éŒ„è£½èªéŸ³æª”ï¼Œè¨­å®šç‚º `5` ç§’ã€‚

    ```bash
    arecord -D plughw:2,0 -f cd -t wav -d 5 -r 16000 test.wav
    ```

<br>

2. è¾¨è­˜èªéŸ³ï¼Œç¬¬ä¸€æ¬¡é‹è¡Œæœƒä¸‹è¼‰ä¸¦ä½¿ç”¨ OpenAI Whisper æ¨¡å‹ tinyï¼Œè‹¥æˆåŠŸæœƒçœ‹åˆ°è¾¨è­˜å‡ºä¾†çš„å…§å®¹é¡¯ç¤ºåœ¨çµ‚ç«¯æ©Ÿã€‚

    ```bash
    whisper test.wav --model tiny --language Chinese
    ```

<br>

3. é—œæ–¼è­¦å‘Šæ˜¯ `Whisper` åµæ¸¬åˆ°ä½¿ç”¨çš„æ˜¯ CPU è€Œé GPUï¼Œæ‰€ä»¥ç„¡æ³•ä½¿ç”¨ `FP16`ï¼Œå°‡è‡ªå‹•æ”¹ç”¨å–®ç²¾åº¦æµ®é»æ•¸ `FP32` åŸ·è¡Œï¼Œé€™ä¸å½±éŸ¿è¾¨è­˜æº–ç¢ºåº¦èˆ‡çµæœï¼Œåªæ˜¯æ•ˆèƒ½ç•¥æ…¢ã€‚

    ![](images/img_11.png)

<br>

## æ•´åˆ Porcupine

_éŒ„éŸ³ â†’ Whisper â†’ å°å‡ºèªéŸ³æ–‡å­—_

<br>

1. å»ºç«‹æ–°çš„è…³æœ¬ `porcupine_wakeup_stt.py`ï¼Œå°ˆæ¡ˆçµæ§‹å¦‚ä¸‹ã€‚

    ```bash
    exPicovoice/
    â”œâ”€â”€ porcupine_wakeup_stt.py
    â”œâ”€â”€ ä½ å¥½æ¨¹è“.ppn
    â”œâ”€â”€ porcupine_params_zh.pv
    ```

<br>

2. ç·¨è¼¯è…³æœ¬ `porcupine_wakeup_stt.py`ã€‚

    ```python
    import pvporcupine
    from pvrecorder import PvRecorder
    import whisper
    import os
    import wave
    import struct
    from datetime import datetime

    ACCESS_KEY     = "<è¼¸å…¥-ACCESS_KEY>"
    KEYWORD_PATH   = "ä½ å¥½æ¨¹è“.ppn"
    MODEL_PATH     = "porcupine_params_zh.pv"
    AUDIO_FILENAME = "recorded.wav"

    def record_audio_with_recorder(recorder, filename, duration_sec, sample_rate):
        num_reads = int(duration_sec * sample_rate / recorder.frame_length)
        pcm_buffer = []
        print("ğŸ™ï¸ é–‹å§‹éŒ„éŸ³â€¦")
        for _ in range(num_reads):
            pcm_buffer.extend(recorder.read())
        print("âœ… éŒ„éŸ³å®Œæˆï¼Œå¯«å…¥æª”æ¡ˆ")
        with wave.open(filename, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(sample_rate)
            wf.writeframes(struct.pack('<' + 'h'*len(pcm_buffer), *pcm_buffer))

    def transcribe_audio(filename):
        if not os.path.exists(filename):
            print("âŒ æ‰¾ä¸åˆ°éŸ³æª”ï¼Œç„¡æ³•è¾¨è­˜ã€‚")
            return
        print("ğŸ§  é–‹å§‹ Whisper è¾¨è­˜â€¦")
        model = whisper.load_model("tiny")
        result = model.transcribe(filename, language="zh")
        print("ğŸ“ è¾¨è­˜çµæœï¼š", result["text"])

    def main():
        porcupine = pvporcupine.create(
            access_key=ACCESS_KEY,
            keyword_paths=[KEYWORD_PATH],
            model_path=MODEL_PATH
        )
        recorder = PvRecorder(
            device_index=-1,
            frame_length=porcupine.frame_length
        )
        recorder.start()
        print("ğŸ§ ç­‰å¾…å–šé†’è©ã€Œä½ å¥½æ¨¹è“ã€â€¦")

        try:
            while True:
                pcm = recorder.read()
                if porcupine.process(pcm) >= 0:
                    print(f"å–šé†’æˆåŠŸï¼Œè«‹åœ¨æç¤ºéŸ³å¾Œé–‹å§‹éŒ„éŸ³ã€‚")
                    # os.system(
                    #     'espeak "Please speak after the beep"'
                    # )
                    # æç¤ºéŸ³ ï¼ˆéœ€å…ˆå®‰è£ soxï¼‰
                    os.system('play -n synth 0.2 sin 1000')

                    # éŒ„éŸ³ä¸¦å­˜æª”
                    record_audio_with_recorder(
                        recorder,
                        AUDIO_FILENAME,
                        duration_sec=5,
                        sample_rate=porcupine.sample_rate
                    )

                    # éŒ„éŸ³çµæŸæç¤º
                    os.system('play -n synth 0.1 sin 1500')
                    print("éŒ„éŸ³çµæŸã€‚")
                    # os.system(
                    #     'espeak "Recording finished."'
                    # )

                    # è½‰æ–‡å­—
                    transcribe_audio(AUDIO_FILENAME)

                    print("å›åˆ°ç­‰å¾…å–šé†’ï¼ˆä½ å¥½æ¨¹è“ï¼‰...")
        except KeyboardInterrupt:
            print("ğŸ›‘ ä½¿ç”¨è€…ä¸­æ–·ï¼Œç¨‹å¼çµæŸã€‚")
        finally:
            recorder.stop()
            recorder.delete()
            porcupine.delete()

    if __name__ == "__main__":
        main()
    ```

<br>

3. åŸ·è¡Œï¼Œå°éº¥å…‹é¢¨èªª `ä½ å¥½æ¨¹è“` å¾Œï¼Œç³»çµ±æœƒéŒ„éŸ³ 5 ç§’ä¸¦è‡ªå‹•è½‰æ›æˆæ–‡å­—é¡¯ç¤ºå‡ºä¾†ã€‚

    ```bash
    python porcupine_wakeup_stt.py
    ```

<br>

## å®˜æ–¹ç‰ˆæœ¬

_Picovoice ä¹Ÿæä¾›äº† Cheetahï¼ˆä¸²æµèªéŸ³è½‰æ–‡å­—ï¼‰å’Œ Leopardï¼ˆæ‰¹æ¬¡èªéŸ³è½‰æ–‡å­—ï¼‰å…©ç¨® on-device STT è§£æ±ºæ–¹æ¡ˆï¼Œä¸éä¸æ”¯æŒä¸­æ–‡ï¼›ä»¥ä¸‹ä»¥ `Cheetah Streaming Speech-to-Text` ç‚ºä¾‹ï¼Œå–ä»£ Whisper å®Œæˆ `å–šé†’ â†’ èªéŸ³è½‰æ–‡å­—`_

<br>

1. å…ˆå®‰è£ Cheetah çš„ Python SDKã€‚

    ```bash
    pip install pvcheetah
    ```

<br>

2. ä¸‹è¼‰ cheetah æ¨¡å‹ã€‚

    ```bash
    wget https://raw.githubusercontent.com/Picovoice/cheetah/master/lib/common/cheetah_params.pv \
        -O cheetah_params.pv
    ```

<br>

3. ç¨‹å¼ç¢¼ã€‚

    ```python
    import pvporcupine
    from pvrecorder import PvRecorder
    import pvcheetah
    import os
    import struct
    from datetime import datetime

    ACCESS_KEY       = "<è¼¸å…¥-ACCESS_KEY>"
    # ä¸‹è¼‰ .ppn
    KEYWORD_PATH     = "ä½ å¥½æ¨¹è“.ppn"
    PORC_MODEL_PATH  = "porcupine_params_zh.pv"
    # éœ€å…ˆä¸‹è¼‰å°æ‡‰å¹³å°çš„ Cheetah æ¨¡å‹
    CHEETAH_MODEL    = "cheetah_params.pv"
    # éŒ„éŸ³é•·åº¦ï¼ˆç§’ï¼‰
    AUDIO_DURATION   = 5


    # å¾ recorder è®€å¹€ï¼Œä¸²æµé€é€² Cheetahï¼Œä¸¦åœ¨ endpoint é–“éš”å¾Œè¼¸å‡ºæ–‡å­—
    def stream_transcribe_with_cheetah(
        recorder, cheetah, duration_sec, sample_rate
    ):
        num_frames = int(duration_sec * sample_rate / recorder.frame_length)
        transcription = ""
        for _ in range(num_frames):
            pcm = recorder.read()
            partial, is_endpoint = cheetah.process(pcm)
            if partial:
                transcription += partial

        # çµæŸå¾Œ flush å‰©é¤˜æ–‡å­—
        final = cheetah.flush()
        if final:
            transcription += final
        return transcription


    # ä¸»è…³æœ¬
    def main():
        # 1. åˆå§‹åŒ– Porcupine & Cheetah
        porcupine = pvporcupine.create(
            access_key=ACCESS_KEY,
            keyword_paths=[KEYWORD_PATH],
            model_path=PORC_MODEL_PATH
        )
        cheetah = pvcheetah.create(
            access_key=ACCESS_KEY,
            model_path=CHEETAH_MODEL
        )

        # 2. å»ºç«‹ Recorderï¼Œä¾›å–šé†’èˆ‡éŒ„éŸ³ä½¿ç”¨
        recorder = PvRecorder(
            device_index=-1, 
            frame_length=porcupine.frame_length
        )
        recorder.start()

        print("ç­‰å¾…å–šé†’è©ã€ä½ å¥½æ¨¹è“ã€‘...")
        try:
            while True:
                pcm = recorder.read()
                if porcupine.process(pcm) >= 0:
                    print(f"å–šé†’æˆåŠŸï¼")
                    # ç›´æ¥ç”¨åŒä¸€ recorder ä¸²æµéŒ„éŸ³é€ Cheetah
                    text = stream_transcribe_with_cheetah(
                        recorder,
                        cheetah,
                        duration_sec=AUDIO_DURATION,
                        sample_rate=porcupine.sample_rate
                    )
                    print("è¾¨è­˜çµæœï¼š", text)
                    print("\nå›åˆ°ç­‰å¾…å–šé†’ã€ä½ å¥½æ¨¹è“ã€‘...")
        except KeyboardInterrupt:
            print("åœæ­¢ç¨‹å¼")
        finally:
            recorder.stop()
            recorder.delete()
            porcupine.delete()
            cheetah.delete()

    if __name__ == "__main__":
        main()
    ```

    ![](images/img_12.png)

<br>

___

_END_

