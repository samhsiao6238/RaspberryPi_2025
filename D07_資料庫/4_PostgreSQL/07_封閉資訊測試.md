# 封閉資訊測試

_驗證是否使用向量查詢的 RAG_

<br>

## 建立封閉資料

1. 進入專案中，建立資料夾 `docs/private_docs/`，內含一個檔案 `sam_notes.txt`。

    ```bash
    cd ~/Documents/exPostgreSQL
    mkdir -p docs/private_docs
    cd docs/private_docs
    touch sam_notes.txt
    ```

<br>

2. 編輯內容。

    ```txt
    作者：Sam  
    內容摘要：Sam 曾於 2025 年 4 月設計一套自動化問答系統，其核心技術為 PostgreSQL + pgvector。  
    該系統使用 LangChain 搭配 OpenAI Embeddings 將筆記內容向量化存入資料庫，最終透過向量比對進行快速查詢。

    這套系統的設計初衷來自於團隊知識庫難以即時搜尋與維護的痛點。Sam 在內部導入 `pgvector` 擴充模組，將每段技術文件內容以 OpenAI 的 `text-embedding-ada-002` 模型轉換為 1536 維的向量，儲存至 PostgreSQL 資料庫中。每筆資料包含 `id`、`content`、`metadata` 與 `embedding` 四欄位，且建立了 `ivfflat` 向量索引以加速近似查詢。

    系統前端以 FastAPI 建立 RESTful API 接口，後端則利用 LangChain 的 `RetrievalQA` 模組串接 ChatOpenAI 模型，讓使用者輸入查詢問題後可取得根據語意相似內容生成的答案。此外，Sam 也為系統加入權重分數過濾機制，避免誤召回語意不符的段落。

    經內部測試，該系統對於 3000 筆技術文檔的查詢準確率達 92%，平均回應時間僅 2.3 秒，大幅超越原本以關鍵字比對實作的查詢模組。此專案目前部署於公司內部私有雲環境，未對外開放，並作為 AI 文件助理產品開發的基礎模組。
    ```

<br>

## 建立腳本

1. 套件安裝。

    ```bash
    pip install llama-index llama-index-vector-stores-postgres llama-index-embeddings-openai llama-index-llms-openai psycopg2-binary python-dotenv
    ```

<br>

2. 建立向量索引並寫入資料庫。

    ```python
    from llama_index.core import VectorStoreIndex, SimpleDirectoryReader
    from llama_index.embeddings.openai import OpenAIEmbedding
    from llama_index.vector_stores.postgres import PGVectorStore
    from dotenv import load_dotenv
    import os

    # 載入環境變數
    load_dotenv()

    # 讀取本地檔案（docs/private_docs/sam_notes.txt）
    documents = SimpleDirectoryReader(
        input_dir="./docs/private_docs"
    ).load_data()

    # 建立 pgvector 儲存
    vector_store = PGVectorStore.from_params(
        database="testdb",
        host="localhost",
        password=os.getenv("POSTGRES_PASSWORD"),
        user="postgres",
        port=5432,
        table_name="documents"
    )

    # 建立索引並存入 pgvector
    index = VectorStoreIndex.from_documents(
        documents,
        embed_model=OpenAIEmbedding(),
        vector_store=vector_store
    )
    ```

<br>

3. 使用向量查詢進行封閉資料檢索。

    ```python
    from llama_index.llms.openai import OpenAI
    llm_model = os.getenv(
        "LLM_MODEL", "gpt-3.5-turbo"
    )
    query_engine = index.as_query_engine(
        llm=OpenAI(model=llm_model)
    )

    # 測試只有資料庫知道的問題
    query = "誰在 2025 年設計過 PostgreSQL + pgvector 問答系統？"

    response = query_engine.query(query)
    print("回答：", response)
    ```

<br>

4. 試著改成非向量資料不存在的內容。

    ```python
    query = "誰在 2019 年使用 Firebase 訓練 LLM？"
    ```

<br>

___

_END_
