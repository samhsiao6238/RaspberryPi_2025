# 分散式運算演練

_使用多台樹莓派建立 `K3s` 叢集進行 `數值計算`，並實際測量效能提升_

## 環境檢查

1. 確認所有節點皆為 Ready

    ```bash
    sudo kubectl get nodes
    ```

    ![](images/img_137.png)

2. 限制 `Job` 不要在 `master` 節點運行，為每台工作節點加上標籤。

    ```bash
    for node in raspi-2025-gray raspi-2025-black raspi-2025-blue; do
        sudo kubectl label node $node role=worker
    done
    ```

    ![](images/img_138.png)

3. 建立命名空間 `pi-workload`，所有後續資源都部署在這個命名空間，方便管理與刪除。

```bash
sudo kubectl create namespace pi-workload
```

## 撰寫 Job 定義

1. 建立腳本。

```bash
cd ~/Documents
nano pi-calculation-job.yaml
```

2. 這個 Job 會透過 Python 計算 π 值，並透過 K3s 自動分配到三台 Raspberry Pi 運行。

    ```yaml
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: pi-calculation-job
      namespace: pi-workload
    spec:
      # 產生 3 個獨立 Pod，並同時執行
      completions: 3
      parallelism: 3
      template:
        spec:
          # 只排程到標籤為 role=worker 的節點上
          nodeSelector:
            role: worker
          # 禁止重新啟動，失敗即視為該任務結束
          restartPolicy: Never
          containers:
          - name: pi-calculator
            image: python:3.9-slim
            command: ["python3", "-c"]
            args:
              - |
                import time, random
                def monte_carlo_pi(n):
                    inside = 0
                    for _ in range(n):
                        x, y = random.random(), random.random()
                        if x*x + y*y <= 1:
                            inside += 1
                    return (inside / n) * 4
                n = 10_000_000
                t0 = time.time()
                pi_est = monte_carlo_pi(n)
                dt = time.time() - t0
                print(f"Node {__import__('socket').gethostname()}: π ≈ {pi_est:.6f}, Time: {dt:.2f}s")
    ```

## 部署與監控

1. 刪除舊的 Job。

```bash
sudo kubectl delete job pi-calculation-job \
    --namespace pi-workload --ignore-not-found
```

1. 套用新的 Job

```bash
sudo kubectl apply -f ~/Documents/pi-calculation-job.yaml
```

3. 觀察 Job 狀態，終端機會卡住，等到 completions 欄顯示 3/3，代表所有 Pod 都執行完畢。

```bash
sudo kubectl get jobs -n pi-workload -w
```

4. 查看 Pod 詳細。

```bash
sudo kubectl get pods -n pi-workload -o wide
```

5. 收集並比較計算時間，看到三行訊息，分別顯示各節點的計算時間；平均時間 ≈ 三者平均，用來代表 `分散式執行單次任務` 的耗時，若想比較 `合併效能`，可用 `3 * 平均時間` 與單機測試時間相較。

```bash
sudo kubectl logs -l job-name=pi-calculation-job -n pi-workload
```

## 單機測試


1. 啟動 Docker Daemon。

```bash
docker -a "Docker"
```

2. 手動拉取映像

    ```bash
    docker pull python:3.9-slim
    ```

3. 使用小樣本快速驗證流程，立刻看到 `Start small test` 與計算結果，就能確定流程無誤。

    ```bash
    time docker run --rm python:3.9-slim python3 - << 'EOF'
    print("Start small test")
    import time, random

    def monte_carlo_pi(n):
        inside = 0
        for _ in range(n):
            x, y = random.random(), random.random()
            if x*x + y*y <= 1:
                inside += 1
        return inside / n * 4

    n = 100_000       # 小樣本 10 萬次
    t0 = time.time()
    pi_est = monte_carlo_pi(n)
    dt = time.time() - t0
    print(f"π≈{pi_est:.6f}, Time: {dt:.2f}s")
    EOF
    ```

4. 大樣本正式測試；先建立運算腳本檔，然後執行並計時（shell 內建 time）

    ```bash
    cat > pi_calc.py <<EOF
    import time, random

    def monte_carlo_pi(n):
        inside = 0
        for _ in range(n):
            x, y = random.random(), random.random()
            if x*x + y*y <= 1:
                inside += 1
        return inside / n * 4

    n = 10_000_000
    t0 = time.time()
    pi_est = monte_carlo_pi(n)
    dt = time.time() - t0
    print(f"π≈{pi_est:.6f}, Time: {dt:.2f}s")
    EOF

    time docker run --rm -v "$PWD/pi_calc.py":/pi_calc.py python:3.9-slim python3 /pi_calc.py
    ```


## 查看輸出

1. Python 腳本內部計算時間，這是程式在容器內實際跑完 `10,000,000` 次蒙地卡羅取樣運算的耗時（Tₛ），應以此作為 `單機基準`。

    ```bash
    π≈3.141308, Time: 1.52s
    ```

2. `time` 指令的整體耗時，其中的 `real` 約 1.78 s，包含了容器啟動與鏡像拉取等額外開銷；`user`/`sys` 則是 CPU 花在用戶態與核心態的時間。

    ```bash
    real    0m1.780s  
    user    0m0.01s  
    sys     0m0.01s
    ```


## 多機效能比較

_自動化取得三台樹莓派上 Job 的計算時間，並快速算出分散式平均耗時、Speed-up 與平行效率。_


1. 從 k3s Master 拷貝 k0ubeconfig

    ```bash
    mkdir -p ~/.kube
    ssh red "sudo cat /etc/rancher/k3s/k3s.yaml" \
        > ~/.kube/k3s.yaml
    ```

2. 編輯 `~/.kube/k3s.yaml`，

```bash
nano ~/.kube/k3s.yaml
```

1. 修改 `server: https://127.0.0.1:6443` 如下。

    ```yaml
    server: https://192.168.1.155:6443
    ```

2. 設定環境變數

    ```bash
    echo >> ~/.zshrc
    echo "# K3s" >> ~/.zshrc
    echo "export KUBECONFIG=~/.kube/k3s.yaml" >> ~/.zshrc
    source ~/.zshrc
    ```

3. 驗證叢集連線

    ```bash
    kubectl get nodes
    ```

2. 取得三個節點的計算時間

```bash
kubectl logs -n pi-workload -l job-name=pi-calculation-job
```

### 3. 建立分析腳本

1. 建立檔案

    ```bash
    nano ~/analyze_pi_perf.sh
    ```

2. 貼上以下內容

    ```bash
    #!/usr/bin/env bash

    # analyze_pi_perf.sh
    # 用法：./analyze_pi_perf.sh <單機耗時秒數> <kubeconfig 路徑> [命名空間] [Job 名稱]
    # 例：./analyze_pi_perf.sh 1.52 ~/.kube/k3s.yaml pi-workload pi-calculation-job

    T_S="$1"
    KUBECONFIG_PATH="$2"
    NAMESPACE="${3:-pi-workload}"
    JOB_NAME="${4:-pi-calculation-job}"

    if [[ -z "$T_S" || -z "$KUBECONFIG_PATH" ]]; then
      cat <<EOF
    錯誤：請傳入單機耗時 (秒) 以及 kubeconfig 路徑，例如：
      $0 1.52 ~/.kube/k3s.yaml pi-workload pi-calculation-job
    EOF
      exit 1
    fi

    export KUBECONFIG="$KUBECONFIG_PATH"

    # 1. 抓 logs 並解析各節點耗時
    TIMES=()
    while IFS= read -r line; do
      # 假設每行都像 "... Time: 4.18s"
      val=$(echo "$line" | awk -F'Time: ' '{print $2}' | sed 's/s$//')
      TIMES+=("$val")
    done < <(kubectl logs -n "$NAMESPACE" -l job-name="$JOB_NAME")

    if [[ "${#TIMES[@]}" -eq 0 ]]; then
      echo "錯誤：未從 kubectl logs 取得任何時間。"
      echo "請確認："
      echo " 1) kubeconfig 是否正確 (server 對應到 k3s master IP)"
      echo " 2) Job 是否已完成 (kubectl get jobs -n $NAMESPACE)"
      exit 1
    fi

    # 2. 計算平均 Tₚ
    N=${#TIMES[@]}
    SUM=0
    for t in "${TIMES[@]}"; do
      SUM=$(echo "$SUM + $t" | bc)
    done
    T_P=$(echo "scale=4; $SUM / $N" | bc)

    # 3. 計算 Speed-up
    SPEEDUP=$(echo "scale=4; $T_S / $T_P" | bc)

    # 4. 計算 Parallel Efficiency
    EFF=$(echo "scale=4; $SPEEDUP / $N" | bc)

    # 5. 輸出結果
    echo "—— 多機效能分析 ——"
    echo "節點數量 (N):        $N"
    echo "各節點耗時 (s):      ${TIMES[*]}"
    echo "分散式平均耗時 Tₚ:  $T_P s"
    echo "單機耗時 Tₛ:         $T_S s"
    echo "Speed-up (Tₛ/Tₚ):    $SPEEDUP"
    echo "Parallel Efficiency: $EFF"
    echo "理論合力 (N×Tₚ):     $(echo "scale=4; $N * $T_P" | bc) s"
    echo "線性加速比 (N×Tₚ/Tₛ): $(echo "scale=4; $N * $T_P / $T_S" | bc)×"
    ```




### 4. 加入執行權限

```bash
chmod +x ~/analyze_pi_perf.sh
```



### 5. 執行並傳入單機耗時

```bash
~/analyze_pi_perf.sh 1.52 ~/.kube/k3s.yaml pi-workload pi-calculation-job
```

* 1.52：單機正式樣本計算得到的秒數
* \~/.kube/k3s.yaml：步驟 1 中設定好的 kubeconfig
* pi-workload / pi-calculation-job：對應你的命名空間與 Job 名稱



### 6. 解讀結果

```text
—— 多機效能分析 ——
節點數量 (N):        3
各節點耗時 (s):      4.18 8.89 4.09
分散式平均耗時 Tₚ:  5.7200 s
單機耗時 Tₛ:         1.52 s
Speed-up (Tₛ/Tₚ):    0.2657
Parallel Efficiency: 0.0886
理論合力 (N×Tₚ):     17.1600 s
線性加速比 (N×Tₚ/Tₛ): 11.2895×
```

* Tₚ：三台 Pi 平均執行 10 000 000 次取樣的時間
* Speed-up：單機 vs 分散式單份任務速度比
* Parallel Efficiency：分散式效能利用率
* N×Tₚ/Tₛ：N 台合力跑 N×10 000 000 次的線性加速比



至此，「多機效能比較」流程完整，並能及時在講義中示範如何自動化取得多節點計算數據並分析結果。
